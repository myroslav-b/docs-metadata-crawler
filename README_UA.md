# docs-metadata-crawler
Паралельний веб-краулер, що спеціалізується на пошуку документів та вилученні метаданих

### Огляд

DocsCrawler - це навчальний веб-краулер, написаний на Go, який виявляє та аналізує файли документів (PDF, DOCX, XLSX, PPTX) з веб-сайтів. Проект демонструє паттерни конкурентного програмування, використання HTTP клієнта, обробку документів та модульний дизайн архітектури в Go.

**⚠️ Навчальна мета**: Цей проект призначений в першу чергу для навчання та демонстрації, а не для продакшн використання.

### Функціональність

- **Конкурентний веб-краулінг**: Багатопотокове виявлення URL з налаштовуваним паралелізмом
- **Аналіз документів**: Витягування метаданих з PDF та документів Microsoft Office
- **Розширювана архітектура**: Легке додавання нових аналізаторів форматів документів
- **JSON вивід**: Структурований вивід метаданих у форматі JSON
- **Налаштовувані параметри**: Інтерфейс командного рядка для кастомізації

### Підтримувані формати документів

- **PDF**: Заголовок, автор, створювач, дата створення, дата модифікації тощо
- **Microsoft Office** (DOCX/XLSX/PPTX): Основні властивості, властивості додатка, статистика

### Встановлення

```bash
# Клонувати репозиторій
git clone https://github.com/yourusername/docscrawler.git
cd docscrawler

# Встановити залежності
go mod tidy

# Зібрати додаток
go build -o docscrawler
```

### Використання

```bash
# Базове використання - сканування сайту для всіх підтримуваних типів документів
./docscrawler -s https://example.com

# Вказати типи документів
./docscrawler -s https://example.com -t pdf -t docx

# Зберегти вивід у файл
./docscrawler -s https://example.com -o results.json

# Налаштувати паралельні потоки
./docscrawler -s https://example.com -p 50
```

#### Опції командного рядка

- `-s, --site`: URL цільового веб-сайту (обов'язково)
- `-t, --type`: Типи документів для аналізу (pdf, docx, xlsx, pptx). Всі типи, якщо не вказано
- `-o, --output`: Шлях до файлу виводу. Виводить в stdout, якщо не вказано
- `-p, --paramax`: Максимальна кількість паралельних потоків (за замовчуванням: 100)

### Архітектура

Проект дотримується модульної архітектури з чітким розділенням обов'язків:

```
├── main.go              # Парсинг CLI та точка входу додатка
├── engine.go            # Координація основного движка краулера
├── crawler.go           # Виявлення URL та парсинг HTML
├── urlstorage.go        # Потокобезпечне управління URL
└── researchers/         # Модулі аналізу документів
    ├── researcher.go    # Спільний інтерфейс та утиліти
    ├── pdf.go          # Аналізатор PDF документів
    └── msox.go         # Аналізатор Microsoft Office
```

#### Ключові компоненти

- **Engine**: Оркеструє процес краулінгу через три фази: crawl, analyze, output
- **URL Storage**: Потокобезпечне сховище виявлених URL зі відстеженням статусу
- **Researchers**: Підключні аналізатори документів, що реалізують спільний інтерфейс
- **Crawler**: Функціональність парсингу HTML та витягування посилань

### Розширення підтримки документів

Додавання підтримки нових форматів документів є простим:

1. Створити новий аналізатор, що реалізує інтерфейс `Researcher`:
```go
type NewDocAnalyzer struct {
    // Поля, специфічні для документа
}

func (nda *NewDocAnalyzer) Do(url string) error {
    // Реалізація обробки документа
}

func (nda *NewDocAnalyzer) OutJSON(writer io.Writer) error {
    // Реалізація JSON серіалізації
}
```

2. Зареєструвати аналізатор в `researchers/researcher.go`:
```go
var allFileTypes = map[string]func() Researcher{
    "pdf":  func() Researcher { return newPdf() },
    "docx": func() Researcher { return newMsox() },
    "newext": func() Researcher { return newNewDocAnalyzer() },
}
```

3. Додати розширення файлу до CLI опцій в `main.go`.

### Тестування

Проект включає комплексні тести, що покривають всі основні компоненти:

```bash
# Запустити всі тести
go test ./...

# Запустити тести з покриттям
./run_tests.sh  # Генерує coverage.html
```

**Примітка**: Тести були в основному написані з допомогою ШІ для демонстрації паттернів тестування та забезпечення надійності коду.

### Залежності

- `golang.org/x/net/html` - Парсинг HTML
- `github.com/pdfcpu/pdfcpu` - Обробка PDF
- `github.com/jessevdk/go-flags` - Парсинг аргументів CLI
- `github.com/stretchr/testify` - Тестовий фреймворк
